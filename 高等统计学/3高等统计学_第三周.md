<head><style>div.solid {border-style:solid;}</style></head>
<b><font size="7">高等统计学——第三周</font></b>

------

# Chapter 2 

[toc]


Preliminaries
-------------


## Some useful results in probability
Let  $\{X_n\},\{Y_n\},X,Y$ be r.v.'s on the same probability space $(\Omega,\mathcal{A},P)$, usless started otherwise.

**Theorem 2.1.1** （Algebraic operations)

1. If $X_n \to_p X$ and $Y_n \to_p Y$, then $X_n \pm Y_n \to_p X \pm Y$ 
2. If $X_n \to X$ a,s. and $Y_ \to Y$ a.s. , then $X_n \pm Y_n \to X \pm Y$ a.s.
3. IF $X_n \to_r X$ and $Y_n \to_r Y$, then $X_n \pm Y_n \to X \pm Y$ 
4. However, suppose that $X_n \to_d X$ and $Y_n \to_d Y$, where all r.v.'s may be defined on different probability spaces. 

   Then it is not true in general that $X_n \pm Y_n \to_d X \pm Y$ 

这个定理说明：依概率收敛、几乎处处收敛、r阶矩收敛都对加减法封闭，但是依分布收敛对加减法不一定封闭

定理第一条的证明思路：



$$
\begin{array}{lll}
	\begin{array}{l}
		X_n \to_p X \\
		Y_n \to_p Y \\
	\end{array}
	&
	\Rightarrow
	&
	X_n\pm Y_n \to_p X \pm Y
	\\
\end{array}
$$ 

$$
\begin{array}{lll}
	P \left\{  \mid X_n + Y_n  - (X+Y)  \mid > \epsilon \right\} \to 0 \\
	\\
	 \mid (X_n - X) + (Y_n -Y)  \mid > \epsilon \\
	 \\
	 \left\{  \mid  (X_n-X) + (Y_n - Y)  \mid > \epsilon \right\} \subset \left\{  \mid X_n -X  \mid > \frac{\epsilon}{2} \right\}\cup \left\{  \mid Y_n -Y  \mid > \frac{\epsilon}{2} \right\} \\
         
         P\left\{  \mid  (X_n-X) + (Y_n - Y)  \mid > \epsilon \right\} \subset P\left\{  \mid X_n -X  \mid > \frac{\epsilon}{2} \right\}\cup P\left\{  \mid Y_n -Y  \mid > \frac{\epsilon}{2} \right\} \\
	 \\
	 \dots \to 0

\end{array}
$$ 

定理最后一条的反例：

$$
\begin{array}{lll}
	\delta \sim N(0,1) \\
	\\
	X_n \to_d \delta \qquad Y_n \to_d -\delta \\
\end{array}
$$ 

令 $X_n$ 与 $Y_n$ 独立同分布

构造  $Y_n \to_d \delta$ 

则 $X_n + Y_n \to_d 0$ 不对，因为 $X_n \pm Y_n$ 的方差为 $2\sigma^2$ ，矛盾

对于减法也一样



<br />
<br />

由上一页的定理最后一条可知，依分布收敛会对加减法不收敛，会给统计带来困扰，如：

$$
t = \frac{ \sqrt{n} (\overline{x}-\mu)}{s} = \frac{\xi_n}{\zeta_n}
$$ 

或者对于统计量 $t_n = X_n +Y_n$ ， 若 $X_n\to_d X,Y_n \to_d Y$ ，不能推出 $X_n + Y_n = t_n \to_d X + Y$ 

即显著性检验方面，不能确定其极限分布

则不能用极限分布去代替分布做假设检验

**Theorem 2.1.2** (Slutsky's Theorem)

Let $X_n \to_d X , Y_n \to_p C$ (i.e. $Y_n \to_d C$). Then

1. $X_n + Y_n\to_d X+C$ 
2. $X_n Y_n \to_d CX$ 
3. $X_n / Y_n \to_d X / C \quad if \quad C \neq 0$

意义：两个随机变量的极限分布，加强某个随机变量的收敛性，即加强 $Y_n$ ，使得其依概率收敛到常数$C$ ，则可以推出部分依分布收敛的加减乘除封闭性

 $$
\begin{array}{lll}
	t = \frac{ \sqrt{n} (\overline{x}-\mu)}{s} = \frac{\xi_n}{\zeta_n} \\
	\xi_n = \sqrt{n} (\overline{x}-\mu) \to_d \sigma N(0,1) \\
	s^2 = \frac{1}{n-1} s\sum (x_i - \overline{x})^2 = \frac{1}{n-1} \sum Y_i \to_p \sigma^2 \quad \text{大数定律} \\
	\downarrow \\
	\zeta_n \to_p \sigma \\
        \\
	\therefore \frac{\xi_n}{\zeta_n} \to_d \frac{\sigma N(0,1)}{\sigma}=N(0,1)
\end{array}
$$ 

<div style="page-break-after: always;"></div>
<br />
<br />


**作业**：证明定理2.1.2的第三条 （从定义开始推导）

Let $X_n \to_d X ,\quad Y_n \to_p C$ (i.e. $Y_n \to_d C$)
> 
> $$
> Y_n \to^{p} C \qquad \forall \epsilon>0 \qquad P \left\{  \mid Y_n - C  \mid > \epsilon \right\} \to 0 \qquad n \to \infty
> $$
>
> $$
> \forall \varepsilon > 0, \forall \delta > 0, \exist N ,while \ n>N \\
> p \{ \mid Y_n - C \mid > \varepsilon \} < \delta
> $$ 
> 
> $$
> X_n \to^{d} X \qquad F_n(x) = P \left\{ X_n \le x \right\} \to P \left\{ X \le x \right\}=F(x) \qquad n \to \infty
> $$
>
> $$
> \forall \varepsilon > 0, \forall \delta > 0, \exist N , while \ n>N	\\
> \mid F_n (x) - F(x) \mid < \delta
> $$

3. $X_n / Y_n \to_d X / C \quad if \quad C \neq 0$

为了证明 $X_n / Y_n \to_d X_n / C$ ，首先证明 $1 / Y_n \to_p 1 / C$ 

$$
\begin{aligned}
	\forall \varepsilon > 0 \\
	P \left\{ \left| \frac{1}{Y_n} - \frac{1}{C} \right| \ge \varepsilon\right\} &= P \left\{   \left|\frac{Y_n - C}{Y_n C}	\right| \ge \varepsilon \right\} \\
	&= P \left\{ \left| \frac{Y_n -C}{C^2 + C(Y_n-C)} \right| \ge \varepsilon ,\left| Y_n - C \right| < \varepsilon \right\} \\
	&\quad + P \left\{ \left| \frac{Y_n -C}{C^2 + C(Y_n-C)} \right| \ge \varepsilon ,\left| Y_n - C \right| \ge \varepsilon \right\} \\
	& \le P \left\{ \left| \frac{Y_n -C}{C^2 - \varepsilon |C|} \right| \ge \varepsilon \right\} + P \left\{ |Y_n -C|\ge \varepsilon \right\}\\
	&= P \left\{ |Y_n-C| \ge (C^2 - \varepsilon |C|) \varepsilon \right\} + P \left\{ |Y_n - C| \ge \varepsilon \right\} \\
	& \to 0 \quad (n\to \infty)
\end{aligned}
$$ 

即 $1 / Y_n \to_p 1 / C$ 

再利用定理第二条即可得 $X_n / Y_n \to_d X_n / C$

<br />
<br />

这个题也可以用连续影射定理来证明

<div style="page-break-after: always;"></div>
<br />
<br />

**Theorem 2.1.3** (Continuous Mapping Theorem) 连续影射定理，若 定理2.1.2不满足，则验证这个定理

Let $X_1,X_2,\cdots$ and $X$ be $k$-dim random vectors, $g:\mathcal{R}^k \to \mathcal{R}$ be continuous. Then

1. $X_n \to_{a.s.} X \quad \Rightarrow  \quad g(X_n) \to_{a.s.} g(X)$ 
2. $X_n \to_p X  \quad \Rightarrow  \quad g(X_n) \to_p g(X)$ 
3. $X_n \to_d X  \quad \Rightarrow  \quad g(X_n)\to_d g(X)$ 


<br />
<br />

例如：
$$
\begin{array}{lll}
	\begin{array}{lll}
		\xi_n \to_d \xi \\
		\zeta_n \to_d \zeta
	\end{array}
	&
	\Rightarrow
	&
	t_n = \frac{\xi_n}{\zeta_n} \to_d \frac{\xi}{\zeta}
\end{array}
$$ 

用连续影射  $g(x,y)=\frac{x}{y} \quad y\neq 0$

$$
t_n = g(\xi_n,\zeta_n)=\frac{\xi_n}{\zeta_n}
$$ 

若能证明 $\left[ \begin{array}{lll}\xi_n \\ \zeta_n \\ \end{array} \right] \to_d  \left[ \begin{array}{lll} \xi \\ \zeta \\ \end{array}\right]$
，证明这个比较麻烦，可以用两种方法：

+ 方法一：由定义，联合分布的连续点收敛到点
+ 方法二：特征函数（随机向量的特征函数 $\varphi(t) = E e^{it' X_n}$ 

首先验证定理2.1.2， 不满足再验证 定理2.1.3

<br />
<br />
<br />

**Examples:**

1. If $X_n\to_d N(0,1)$, then $X_n^2 \to_d N^2(0,1)=\chi_1^2$ 
2. If $(X_n,Y_n)\to_d N(0,1)$, then $X_n / Y_n \to_d$ Cauchy.

Proof.

Let $(X,Y)\to_d N(0,I)$, then $X,Y$ are independent

$X / Y\to_d$ Cauchy, and $P(g(X,Y)) := X /Y$ is discontinous

<br />
<br />
<br />

<div style="page-break-after: always;"></div>
<br />
<br />


## Order relations

Order relations could greatly simplify writings in a proof.

**Definition**

Let $\{a_n\}$ 's and $\{b_n\}$ 's be two sequences.

+ $a_n = O(b_n) \quad \Longleftrightarrow  \quad \mid a_n / b_n  \mid \le C  \quad \Longleftrightarrow  \quad \limsup  \mid a_n / b_n  \mid < \infty$ 
+ $a_n = o(b_n)   \quad \Longleftrightarrow  \quad a_n / b_n \to 0$ 
+ $a_n \sim b_n  \quad \Longleftrightarrow  \quad a_n / b_n \to 1$

**Definition** [Stochastic orders]

Let  $\{X_n\}$ 's and $\{Y_n\}$ 's be two sequences of r.v.'s

+ $X_n = O_p(1)$

    $\Longleftrightarrow \forall \epsilon >0, \exists M_{\epsilon},N_{\epsilon}, \forall n\ge N_{\epsilon}\qquad P \left( |X_n|>M_{\epsilon} \right)< \epsilon$ 

    $\qquad$即超过 $M_{\epsilon}$ 的概率不超过 $\epsilon$ 

    $\Longleftrightarrow \forall \epsilon>0, \exists M_{\epsilon} \qquad sup_n P (|X_n|>M_{\epsilon})<\epsilon$ 

    $\Longleftrightarrow \lim_{M \to \infty} \limsup_{n} P(|X_n|>M)=0$ ("tightness")

+ $X_n = O_p(Y_n) \quad if \quad X_n / Y_n =O_p(1)$ 

+ $X_n = o_p(1) \qquad if \quad X_n \to_p 0$ 

+ $X_n = o_p(Y_n) \qquad if \quad X_n / Y_n = o_p(1)$ 分子收敛于0的速度比分母快


将数列的无穷小转化为概率的无穷小

在皮亚诺余项的泰勒公式里面有应用

<br />
<br />

**Remark 2.2.1** If $X_n=O_p(1)$ , we say that $\{X_n\}$ is "stochastically bounded", or is "tight". It means that no mass will escape to $\infty$ with positive probability.

随机有界：不存在能够逃到无穷大的点序列

随机不有界：...

例：不是$O_p(1)$ 的序列 $\{x_n\}$

$$
X_n = \left\{ \begin{array}{lll} n & \frac{1}{2}\\ 0 & \frac{1}{2} \end{array}\right.
$$ 

令 $\epsilon=0.1$ 

$$
\left\{ \begin{array}{lll} p \left\{ |X_n| > M_{0.1}\right\}<0.1 \text{不成立}  & \text{找} M_{0.1}\\ \forall n > N \text{令} N=10000,n=100000 ,p \left\{ |X_{100000}|>M_{0.1} \right\}=\frac{1}{2 } \text{不成立} & \text{找} N \end{array}\right.
$$ 

即有一个点概率会逃到无穷大


<br />
<br />

**Theorem 2.2.1**

+ If $X_n \to_d X$, then $X_n = O_p(1)$ 

+ If $X_n =o_p(1)$, then $X_n = O_p(1)$ 

Proof. 没看懂...似乎是数学分析的一个课后习题

例： 

> 定义 $X_n= \frac{ \sqrt{n} (\overline{x}-\mu)}{\sigma} \to_d N(0,1)$ 
> 
> 则 $X_n = O_p(1)$ 不会有概率逃到 $\infty$ 
> 
> 则 $\frac{\overline{x}-\mu}{\sigma}=O_p(\frac{1}{ \sqrt{n} })$
>> 由定义 $X_n = O_p(Y_n) \quad \Rightarrow X_n /Y_n = O_p(1)$
> 
> 则 $\overline{x}-\mu=O_p(\frac{1}{ \sqrt{n} })$ $\qquad \sigma$ 是常数

大数定理：样本均值很靠近总体均值

中心极限定理：样本均值与总体均值的距离大致为 $\frac{1}{ \sqrt{n} }\to$阶数

中心极限定理可以告诉我们更多的信息，如果样本n为100，则距离大致为0.1

**Exercises 2.3**

1. Check whether the following statements are true or false. Wither prove your claim or given a counter-example.

   a. If $X_n \to_p X$ and $Y_n \to_p Y \Rightarrow X_nY_n \to_p XY$
   
   b. If  $X_n \to_{a.s.} X$ and $Y_n \to_{a.s.} \Rightarrow X_nY_n \to_{a.s.} XY$ 

   c. If $X_n \to X$ in $L_r$ and $Y_n \to Y$ in $L_r (r>0) \quad \Rightarrow X_nY_n \to XY$ in $L_r$ 

   d. If $X_n\to_d X$ and $Y_n \to_d Y \quad \Rightarrow X_nY_n \to_d X Y$

2. What happens if we replace the operation of multiplication by that of division in the last question?

3. Prove the equivalence of several definitions for $X_n=O_p(1)$ given in the notes.

<br />
<br />
<br />

作业：证明

+ $O_p(1) \times o_p(1) = o_p(1)$ 
+ $O_p(1) \times O_p(1) = O_p(1)$ 

> 从定义出发

令

$$
\begin{aligned}
	X_n = o_p(1) &\Rightarrow X_n \to_p 0\\
	    & \Rightarrow p \left\{ |X_n|>\delta \right\}\to 0 \\
	    & \Rightarrow P \left\{ |X_n|>\delta\right\}< \epsilon \qquad \forall n \ge N_{\epsilon} \\
	Y_n = O_p(1) & \Rightarrow \forall \epsilon >0 \quad \exists M_{\epsilon},N_{\epsilon} \\
	    &\quad P \left\{ |Y_n|>M_{\epsilon} \right\}< \epsilon \\
	Z_n = O_p(1) & \Rightarrow \forall \epsilon >0 \quad \exists M_{\epsilon},N_{\epsilon} \\
	    &\quad P \left\{ |Z_n|>M_{\epsilon} \right\}< \epsilon \\

\end{aligned}
$$ 

则 $\forall \delta>0, \exists M_{\epsilon},M_{\epsilon_1}, \ s.t.$
$$
\begin{aligned}
	P \left\{ |X_n Y_n|> \delta \right\} &= P \left\{ |X_n| \times |Y_n|> \delta \right\} \\
	    &= P \left\{  |X_n| \times |Y_n|> \delta ,|Y_n|>M_{\epsilon} \right\} + P \left\{ |X_n| \times |Y_n|> \delta ,|Y_n| \le M_\epsilon \right\}\\
	    & \le P \left\{ M_{\epsilon} \times |X_n|>\delta \right\}+P \left\{ |Y_n|>M_{\epsilon} \right\} \\
	    & \le 2\epsilon
\end{aligned}
$$ 

$$
\begin{aligned}
	P \left\{ |Z_n Y_n|>M_{\epsilon} \right\} &= P \left\{ |Z_n | \times |Y_n|> M_{\epsilon} \right\} \\
	    &= P \left\{ |Z_n | \times |Y_n|> M_{\epsilon} ,|Z_n|>M_{\epsilon_1} \right\}+ P \left\{ |Z_n | \times |Y_n|> M_{\epsilon} ,|Z_n| \le M_{\epsilon_1} \right\} \\
	    &\le P \left\{ |Z_n|>M_{\epsilon_1} \right\} + P \left\{ M_{\epsilon_1}|Y_n| > M_{\epsilon} \right\} \\
	    & < 2\epsilon
\end{aligned}
$$ 

<div style="page-break-after: always;"></div>
<br />
<br />

# Chapter 3  


Central Limit Theorems and Related Refinements
------

Limit theorems for sums of independent r.v.'s occupy a special place in probability and mathematical statistics.

First of all, they are the simplest case to study.

Second, the theory for sums of independent r.v.'s are the most complete.

Third, studies on sum of independent r.v.'s can shed light on other classes of statistics such as the function of the sum of independent r.v.'s, $U$-statistics, $L$-statistics and symmetric statistics, etc.

中心极限定理在概率论和数理统计中由重要的地位，它简单、完整，而且还能引领其余统计学领域的发展，比如独立随机变量的和、U统计量、L
统计量、对称统计量等等

<br />
<br />

In this chapter, we shall discuss some important issues concerning the sum of independent r.v.'s.

In particular, we shall discuss the asymptotic normality, Berry_Esseen bounds (uniform or nonuniform), Edgeworth expansions (uniform or nonuniform), large deviations and saddlepoint approximations, and others.

This will pave the way for other classes of statistics.

本章将讨论有关独立随机变量的总和的一些重要问题。
特别是，我们将讨论渐近正态性，Berry_Esseen边界（一致或不一致），Edgeworth展开（一致或不一致），大偏差和鞍点近似等。
这是其他类别的统计的基础。

<div style="page-break-after: always;"></div>
<br />
<br />


## 3.1.1 CLT for i.i.d.  r.v.s
独立随机变量的中心极限定理

When $X_1,\cdots,X_n$ are i.i.d., we get the following simple CLT.

**Theorem 3.1.1** (levy theorem)

Let $X_1,\cdots,X_n$ be i.i.d. r.v.;s with $EX_1=0, \sigma^2=EX_1^2< \infty$ 

Let $F_n(x) = p \left(  \sqrt{n} \overline{X} / \sigma \le x \right)$ 

Then

$$
sup_{x \in R} |F_n(x) - \Phi(x) | \to 0 
$$ 

> $$
> \frac{ \sqrt{n} \overline{x}}{\sigma} =\sum \left( \frac{x_i}{ \sqrt{n} \sigma} \right) \triangleq \sum_{i=1}^{n} Y_i \qquad \left\{ \begin{array}{lll} E(Y_i) = 0 \\ Var(Y_i) = \frac{1}{n} \\ Var( \sum Y_i) =1 \end{array} \right.
> $$ 

## 3.1.2 CLT for triangular arrays with finite variances

The following theorem states that a sum of a large number of small independent effects has approximately a normal distribution.

大量小的独立效应之和大约具有正态分布。

**Theorem 3.1.2** (Lindeberg-Feller CLT)

For each $n$, 

Let $X_{n,k},  1\le k \le n$ be independent r.v.s with $EX_{n,k}=0$ and $\sum_{k=1}^n \sigma^2_{n.k} := \sum_{k=1}^n EX^2_{n,k}=1$.

Denote $F_n(x) = P \left( \sum_{m=1}^{n} X_{n,k}\le x \right)$. 

Then the following two statements are equivalent.

1. The Lindeberg condition holds: 截尾二阶矩趋于0

   $$
   \forall \epsilon>0: \lim_{n \to \infty} \sum_{k=1}^{n} EX^2_{n,k} I \left\{ |X_{n,k}|\ge \epsilon \right\}=0
   $$ 

2. 
   a. $\max_{1\le k \le n}\sigma^2_{n,k} \to 0$

   b. $\sup_{x \in R} |F_n(x)- \Phi(x) | \to 0$ 

<br />
<br />

对于$\sum_{k=1}^{n} \sigma^2_{n,k}=1$ 这个条件来说，会存在两种情况

1. 所有$\sigma^2_{n,k}$ 都差不多
2. 某一个或几个 $\sigma^2_{n,k}$ 相对于其余的来说比较大

而$\max_{1\le k \le n}\sigma^2_{n,k} \to 0$这个就说明，不会存在第二种情况。

**Remark 3.1.1** Clearly, the Lindeberg condition implies that
$$
\forall \epsilon >0: \lim_{n \to \infty}  \sum_{m=1}^{n} P(|X_{n,k}|\ge \epsilon) =0
$$ 
which further implies that
$$
\forall \epsilon > 0: \sup_n P(|X_{n,k}| ge \epsilon) \to 0
$$ 
That is, all the individual terms $X_{n,k}$ are uniformly small.

<br />
<br />


三角列：
$$
\begin{array}{llllll}
	x_{1,1} &&&&& \to \sum_{k=1}^{1} x_{n,k}\\
	x_{2,1} & x_{2,2} &&&& \to \sum_{k=1}^{2} x_{n,k}\\
	x_{3,1} & x_{3,2} & x_{3,3} &&& \to \sum_{k=1}^{3} x_{n,k} \\
	\vdots \\
	x_{n,1} & x_{n,2} & x_{n,3} & \cdots & x_{n,n} & \to \sum_{k=1}^{n} x_{n,k}\\
\end{array}
$$ 

在这个定理中，只要求 $x_{n,k}$ 独立（ $n$ 固定），可以不同分布

期望为0，方差为1不是一个限制条件，可以自己构造一下

三角列的中心极限定理：研究三角阵随机变量的行和的分布

相对于 levy CLT, Lindeberg-Feller CLT 的好处是

1. 对行和不要求同分布
2. 给了一个充要条件

<br />
<br />


**Theorem 3.1.3** Lyapunov CLT

For each $n$ 

Let $X_{n,k}, 1 \le k \le n$, be independent r.v.s with $EX_{n,k}=0$ and $\sum_{k=1}^{n} \sigma^2_{n,k}:= \sum_{k=1}^{n} EX^2_{n,k}=1$.

Denote $F_n(x) = P( \sum_{m=1}^{n} X_{n,k} \le x)$ 

If 
$$
\sum_{k=1}^{n} E|X_{n,k}|^{2+\delta} \to 0
$$ 

Then
$$
\sup_{x \in R} |F_n(x)- \Phi(x) | \to 0
$$ 

Proof.

> The Lindeberg condition helds since
> 
> $$
> \begin{aligned}
>     \sum_{k=1}^{n} EX^2_{n,k} I \left\{ |X_{n,k}|\ge \epsilon \right\} &\le \frac{1}{\epsilon^{\delta}} \sum_{k=1}^{n} E |X_{n,k}| ^{2+\delta} I \left\{ |X_{n,k}|\ge \epsilon \right\} \\
>	& \le \frac{1}{\epsilon^{\delta}} \sum_{k=1}^{n} E |X_{n,k}|^{2+\delta} \\
>	& \to 0
> \end{aligned}
> $$ 

Lyapunov 条件 $\sum_{k=1}^{n} E|X_{n,k}|^{2+\delta} \to 0$

代价： $2+delta$ 阶矩存在

而 L-F条件只需要2阶矩存在

省略一点东西...

<br />
<br />

**An application: CLT for independent r.v.s**

<br />
<br />

**Lindeberg-Feller CLT**

<br />
<br />

**Lyapunov CLT**

<div style="page-break-after: always;"></div>
<br />
<br />


## 3.2 Uniform Berry-Esseen Bounds

给出了CLT下的收敛速度

$X_1,X_2,...,X_n$ independent r.v.'s

$E(X_j)=0$

$E|X_j|^{2+\delta}< \infty$ for some $0<\delta\le 1 (j=1,2,...,)$ 

$$
EX_j^2 = \sigma_j^2 \quad B^2_n = \sum_{j=1}^{n}  \sigma_j^2 \quad L_{n,\delta} = \frac{\sum_{j=1}^{n} E|X_j|^{2+\delta}}{B_n^{2+\delta}} 
$$ 


In particular, in i.i.d. case, where $EX^2_j = \sigma^2$, we have （独立同分布，把上面的替换一下）

$$
B^2_n = n \sigma^2 \quad L_{n,\delta} = \frac{nE|X_1|^{2+\delta}}{(n \sigma^2)^{\frac{2+\delta}{2}}} = \frac{C}{n^{\delta / 2}} \quad L_{n,1} = \frac{C}{n^{1 /2}}
$$ 

<br />
<br />


**Theorem 3.2.1** (Berry-Essen bounds for indenpendent r.v.'s) 独立的情况

Let $X_1,X_2,...X_n$ be independent r.v.'s such that $EX_j=0$ and $E|X_j|^{2+\delta} < \infty$ for some $0<\delta\le 1$.

Put 

$$
L_{n, \delta} = B^{-(2+\delta)}_n \sum_{j=1}^{n} E|X_j|^{2+\delta} = \frac{\sum_{j=1}^{n} E|X_j|^{2+\delta}}{B_n^{2+\delta}}
$$ 

Then for all $n$ 

$$
\sup_{x \in \R} |F_n(x) - \Phi(x)| \le AL_{n,\delta}
$$ 
<br />
<br />


**Theorem 3.2.2** (Berry-Essen bounds for iid. r.v.'s) 独立同分布的情况

Let $X_1,...,X_n$ be i.i.d r.v.'s

Let $\delta \in (0,1] \quad EX_1=0 \quad EX_1^2 = \sigma^2 >0 \quad E|X_1|^{2+\delta}< \infty \quad \rho_{\delta} = E|X_1|^{2+\delta} / \sigma^{2+\delta}$

Then for all $n$,

$$
\sup_{x \in \R} |F_n(x) - \Phi(x)| \le \frac{A \rho_{\delta}}{n^{\delta / 2}}
$$ 

> 由上面的情况可以立即推出引理3.2.2
> 
> **Coeollary 3.2.2** Let $X_1,X_2,...,X_n$ be i.i.d. r.v.'s
> 
> Let $\delta =1  \quad EX_1=0 \quad EX_1^2 = \sigma^2 >0 \quad E|X_1|^3< \infty \quad \rho = E|X_1|^{3} / \sigma^{3}$
> 
> Then for all $n$,
> 
> $$
> \sup_{x \in \R} |F_n(x) - \Phi(x)| \le \frac{A \rho_{\delta}}{\sqrt{n}}
> $$ 


<div style="page-break-after: always;"></div>
<br />
<br />


## 3.3 Non-Uniform Berry-Essen Bounds

